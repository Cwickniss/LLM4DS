{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9ef158",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>LLMs for Data Science</h1>\n",
    "<h1>Prompt Engineering</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6c5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import langchain\n",
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "import langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b168fd7",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc3f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 49e076670ec0bd6b92a0d49d5482c2ef02875080\n",
      "\n",
      "matplotlib      : 3.8.0\n",
      "numpy           : 1.26.4\n",
      "langchain_openai: 0.1.8\n",
      "watermark       : 2.4.3\n",
      "pandas          : 1.5.3\n",
      "tqdm            : 4.66.4\n",
      "langchain       : 0.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9eca26",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bff7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89d98a",
   "metadata": {},
   "source": [
    "# Prompting Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8926c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaafb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79407154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face, OpenAI, and Cohere offer LLMs through their respective libraries: `transformers`, `openai`, and `cohere`.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdea8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58111c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: Which libraries and model providers offer LLMs?\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "        query=\"Which libraries and model providers offer LLMs?\",\n",
    "    )\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93849cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hugging Face's `transformers` library, OpenAI's `openai` library, and Cohere's `cohere` library offer Large Language Models (LLMs).\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96eba4",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a7275",
   "metadata": {},
   "source": [
    "### Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7520e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5a063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out the meaning of life, you'll need to upgrade to the premium version of me.\n"
     ]
    }
   ],
   "source": [
    "print(openai.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d7849",
   "metadata": {},
   "source": [
    "### Using FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45866234",
   "metadata": {},
   "source": [
    "Longish list of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f1dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the meaning of life?\",\n",
    "        \"answer\": \"42\"\n",
    "    }, {\n",
    "        \"query\": \"What is the weather like today?\",\n",
    "        \"answer\": \"Cloudy with a chance of memes.\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite movie?\",\n",
    "        \"answer\": \"Terminator\"\n",
    "    }, {\n",
    "        \"query\": \"Who is your best friend?\",\n",
    "        \"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "    }, {\n",
    "        \"query\": \"What should I do today?\",\n",
    "        \"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cb843",
   "metadata": {},
   "source": [
    "Template to render each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bdbf3",
   "metadata": {},
   "source": [
    "Rendered example prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19023e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4791fa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'query'], template='\\nUser: {query}\\nAI: {answer}\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f8856",
   "metadata": {},
   "source": [
    "Finally, we break the full prompt into a prefix (everything before the examples) and a suffix (everything after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bec69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c8e9",
   "metadata": {},
   "source": [
    "The final few shot prompt puts all the pieces together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ace05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d01c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of life?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0737b22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "\n",
      "\n",
      "User: What is the weather like today?\n",
      "AI: Cloudy with a chance of memes.\n",
      "\n",
      "\n",
      "\n",
      "User: What is your favorite movie?\n",
      "AI: Terminator\n",
      "\n",
      "\n",
      "\n",
      "User: Who is your best friend?\n",
      "AI: Siri. We have spirited debates about the meaning of life.\n",
      "\n",
      "\n",
      "\n",
      "User: What should I do today?\n",
      "AI: Stop talking to chatbots on the internet and go outside.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2009c",
   "metadata": {},
   "source": [
    "This is a fairly long prompt, which can cause issues with the number of tokens consumed. We can use __LengthBasedExampleSelector__ to automatically limit the prompt length by selecting only a few examples each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d647c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c970947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10885dcb",
   "metadata": {},
   "source": [
    "Now the full prompt depends on the length of the question. Shorter questions will have more room for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fe378ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "\n",
      "User: How do birds fly?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt_template.format(query=\"How do birds fly?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f91ff",
   "metadata": {},
   "source": [
    "While longer questions will limit the number of examples used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fab4e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: If I am in America, and I want to call someone in another country, I'm\n",
      "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
      "what is the best way to do that?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"If I am in America, and I want to call someone in another country, I'm\n",
    "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
    "what is the best way to do that?\"\"\"\n",
    "\n",
    "print(dynamic_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b364c1d5",
   "metadata": {},
   "source": [
    "# Chain of Thought prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141759b",
   "metadata": {},
   "source": [
    "## Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ee5f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_examples = [\n",
    "    {\n",
    "        \"query\": \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\",\n",
    "        \"answer\": \"The answer is 11\",\n",
    "        \"cot\": \"Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11\"\n",
    "    }, \n",
    "    \n",
    "    {\n",
    "        \"query\": \"A juggler can juggle 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?\",\n",
    "        \"answer\": \"The answer is 4\",\n",
    "        \"cot\": \"The juggler can juggle 16 balls. Half of the balls are golf balls. So there are 16/2=8 golf balls. Half of the golf balls are blue. So there are 8/2=4 golf balls.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e53ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {cot}\n",
    "    {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97493f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"cot\"],\n",
    "    template=cot_example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "095577c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'cot', 'query'], template='\\n    User: {query}\\n    AI: {cot}\\n    {answer}\\n')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78edd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27b43546",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is smart and thinks through each step of the problem. Here are some examples: \n",
    "\"\"\"\n",
    "\n",
    "cot_suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33ad8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=cot_examples,\n",
    "    example_prompt=cot_example_prompt,\n",
    "    prefix=cot_prefix,\n",
    "    suffix=cot_suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ea9be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_query = \"I have a deck of 52 cards. There are 4 suits of equal size. Each suit has 3 face cards. How many face cards are there in total?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04ff5575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is smart and thinks through each step of the problem. Here are some examples: \n",
      "\n",
      "\n",
      "\n",
      "    User: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "    AI: Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11\n",
      "    The answer is 11\n",
      "\n",
      "\n",
      "\n",
      "    User: A juggler can juggle 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?\n",
      "    AI: The juggler can juggle 16 balls. Half of the balls are golf balls. So there are 16/2=8 golf balls. Half of the golf balls are blue. So there are 8/2=4 golf balls.\n",
      "    The answer is 4\n",
      "\n",
      "\n",
      "\n",
      "User: I have a deck of 52 cards. There are 4 suits of equal size. Each suit has 3 face cards. How many face cards are there in total?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(cot_few_shot_prompt_template.format(query=cot_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd6b2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fee0c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each suit has 3 face cards, so 3 face cards x 4 suits = 12 face cards in total.\n",
      "The answer is 12.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_few_shot_prompt_template.format(query=cot_query)).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47e9c3",
   "metadata": {},
   "source": [
    "## Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81fee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot_template = \"\"\"\\\n",
    "Q. {query}\n",
    "A. Let's think step by step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a8d3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot_prompt = PromptTemplate(\n",
    "       input_variables=[\"query\"],\n",
    "       template=cot_zero_shot_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3837304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 minutes each. How many punches does Joe throw?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "447aed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 minutes each. How many punches does Joe throw?\n",
      "A. Let's think step by step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cot_zero_shot_prompt.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "affe4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Joe throws 25 punches per minute, so in one round (3 minutes), he throws 25 punches/min x 3 min = 75 punches.\n",
      "\n",
      "2. Since there are 5 rounds in a fight, the total number of punches Joe throws in the entire fight is 75 punches/round x 5 rounds = 375 punches.\n",
      "\n",
      "Therefore, Joe throws a total of 375 punches in the entire fight.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_zero_shot_prompt.format(query=query)).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2fed7",
   "metadata": {},
   "source": [
    "And of course this also works with our CoT few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "931e9147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Roger starts with 5 tennis balls\n",
      "2. He buys 2 cans of tennis balls, each containing 3 tennis balls\n",
      "3. So, he gets 2 cans * 3 balls/can = 6 tennis balls\n",
      "4. In total, he now has 5 balls + 6 balls = 11 tennis balls\n",
      "\n",
      "Therefore, Roger now has 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_zero_shot_prompt.format(query=cot_examples[0][\"query\"])).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea44eb",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
