{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38924fbc",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>LLMs for Data Science</h1>\n",
    "<h1>Prompt Engineering</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de31467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import langchain\n",
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "import langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721940c",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a838e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 029419f525238e1b9a7c22f96809155546a701ad\n",
      "\n",
      "langchain       : 0.2.2\n",
      "watermark       : 2.4.3\n",
      "langchain_openai: 0.1.8\n",
      "matplotlib      : 3.8.0\n",
      "numpy           : 1.26.4\n",
      "tqdm            : 4.66.4\n",
      "json            : 2.0.9\n",
      "pandas          : 1.5.3\n",
      "nltk            : 3.8.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e708dc",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f367ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb858b1c",
   "metadata": {},
   "source": [
    "# Prompting Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c1e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be82c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd872d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c03d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9cdac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: Which libraries and model providers offer LLMs?\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "        query=\"Which libraries and model providers offer LLMs?\"\n",
    "    )\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369c1bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hugging Face's `transformers` library, OpenAI's `openai` library, and Cohere's `cohere` library offer LLMs.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4eaa7f",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024660a",
   "metadata": {},
   "source": [
    "### Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e491c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf91722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm still trying to figure that out myself. Maybe we can team up and solve the mystery together.\n"
     ]
    }
   ],
   "source": [
    "print(openai.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999d7d4",
   "metadata": {},
   "source": [
    "### Using FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb88e1",
   "metadata": {},
   "source": [
    "Longish list of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1328b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the meaning of life?\",\n",
    "        \"answer\": \"42\"\n",
    "    }, {\n",
    "        \"query\": \"What is the weather like today?\",\n",
    "        \"answer\": \"Cloudy with a chance of memes.\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite movie?\",\n",
    "        \"answer\": \"Terminator\"\n",
    "    }, {\n",
    "        \"query\": \"Who is your best friend?\",\n",
    "        \"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "    }, {\n",
    "        \"query\": \"What should I do today?\",\n",
    "        \"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772a490",
   "metadata": {},
   "source": [
    "Template to render each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ac1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e71f2",
   "metadata": {},
   "source": [
    "Rendered example prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc0d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc2aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'query'], template='\\nUser: {query}\\nAI: {answer}\\n')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c17bc",
   "metadata": {},
   "source": [
    "Finally, we break the full prompt into a prefix (everything before the examples) and a suffix (everything after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f89904",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbf6fd",
   "metadata": {},
   "source": [
    "The final few shot prompt puts all the pieces together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ba28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed17355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of life?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c651d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "\n",
      "\n",
      "User: What is the weather like today?\n",
      "AI: Cloudy with a chance of memes.\n",
      "\n",
      "\n",
      "\n",
      "User: What is your favorite movie?\n",
      "AI: Terminator\n",
      "\n",
      "\n",
      "\n",
      "User: Who is your best friend?\n",
      "AI: Siri. We have spirited debates about the meaning of life.\n",
      "\n",
      "\n",
      "\n",
      "User: What should I do today?\n",
      "AI: Stop talking to chatbots on the internet and go outside.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719a36a",
   "metadata": {},
   "source": [
    "This is a fairly long prompt, which can cause issues with the number of tokens consumed. We can use __LengthBasedExampleSelector__ to automatically limit the prompt length by selecting only a few examples each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db6a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553da178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0286d",
   "metadata": {},
   "source": [
    "Now the full prompt depends on the length of the question. Shorter questions will have more room for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "241c33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "\n",
      "User: How do birds fly?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt_template.format(query=\"How do birds fly?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d701796",
   "metadata": {},
   "source": [
    "While longer questions will limit the number of examples used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4916382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: If I am in America, and I want to call someone in another country, I'm\n",
      "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
      "what is the best way to do that?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"If I am in America, and I want to call someone in another country, I'm\n",
    "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
    "what is the best way to do that?\"\"\"\n",
    "\n",
    "print(dynamic_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385d2de",
   "metadata": {},
   "source": [
    "# Chain of Thought prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7dcdd",
   "metadata": {},
   "source": [
    "## Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c08030",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_examples = [\n",
    "    {\n",
    "        \"query\": \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\",\n",
    "        \"answer\": \"The answer is 11\",\n",
    "        \"cot\": \"Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11\"\n",
    "    }, \n",
    "    \n",
    "    {\n",
    "        \"query\": \"A juggler can juggle 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?\",\n",
    "        \"answer\": \"The answer is 4\",\n",
    "        \"cot\": \"The juggler can juggle 16 balls. Half of the balls are golf balls. So there are 16/2=8 golf balls. Half of the golf balls are blue. So there are 8/2=4 golf balls.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca106cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {cot}\n",
    "    {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74eb07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"cot\"],\n",
    "    template=cot_example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "215397c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'cot', 'query'], template='\\n    User: {query}\\n    AI: {cot}\\n    {answer}\\n')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52772f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a20def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is smart and thinks through each step of the problem. Here are some examples: \n",
    "\"\"\"\n",
    "\n",
    "cot_suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "343c45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=cot_examples,\n",
    "    example_prompt=cot_example_prompt,\n",
    "    prefix=cot_prefix,\n",
    "    suffix=cot_suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c6f7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_query = \"I have a deck of 52 cards. There are 4 suits of equal size. Each suit has 3 face cards. How many face cards are there in total?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c717444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is smart and thinks through each step of the problem. Here are some examples: \n",
      "\n",
      "\n",
      "\n",
      "    User: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "    AI: Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11\n",
      "    The answer is 11\n",
      "\n",
      "\n",
      "\n",
      "    User: A juggler can juggle 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?\n",
      "    AI: The juggler can juggle 16 balls. Half of the balls are golf balls. So there are 16/2=8 golf balls. Half of the golf balls are blue. So there are 8/2=4 golf balls.\n",
      "    The answer is 4\n",
      "\n",
      "\n",
      "\n",
      "User: I have a deck of 52 cards. There are 4 suits of equal size. Each suit has 3 face cards. How many face cards are there in total?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(cot_few_shot_prompt_template.format(query=cot_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0a289c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a869f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each suit has 3 face cards, so there are 4 suits x 3 face cards = 12 face cards in total.\n",
      "The answer is 12.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_few_shot_prompt_template.format(query=cot_query)).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaa71b",
   "metadata": {},
   "source": [
    "## Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e40a6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot_template = \"\"\"\\\n",
    "Q. {query}\n",
    "A. Let's think step by step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45b5eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot_prompt = PromptTemplate(\n",
    "       input_variables=[\"query\"],\n",
    "       template=cot_zero_shot_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfb53215",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 minutes each. How many punches does Joe throw?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e89b23a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 minutes each. How many punches does Joe throw?\n",
      "A. Let's think step by step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cot_zero_shot_prompt.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed1ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. In one round, Joe throws 25 punches per minute, so in a 3 minute round, Joe throws 25 x 3 = 75 punches.\n",
      "\n",
      "2. Since there are 5 rounds in the fight, Joe will throw 75 punches x 5 rounds = 375 punches in total. \n",
      "\n",
      "Therefore, Joe throws 375 punches in the entire fight.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_zero_shot_prompt.format(query=query)).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dcc75",
   "metadata": {},
   "source": [
    "And of course this also works with our CoT few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7c55ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Roger starts with 5 tennis balls.\n",
      "2. He buys 2 cans of tennis balls, with each can containing 3 tennis balls.\n",
      "3. So, he adds 2 cans x 3 balls per can = 6 tennis balls from the new cans.\n",
      "4. Therefore, Roger now has a total of 5 + 6 = 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(cot_zero_shot_prompt.format(query=cot_examples[0][\"query\"])).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67ceac",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
